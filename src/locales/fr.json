{
  "nav": {
    "home": "Profil",
    "education": "Formation",
    "experience": "Exp√©rience",
    "projects": "Projets",
    "contact": "Contact",
    "skills": "Comp√©tences",
    "resume": "CV"
  },

  "ui": {
  "read_more": "Lire plus",
  "read_less": "Lire moins"
  },

  "footer": {
    "cv": "CV",
    "demo": "D√©mo",
    "code": "Code",
    "resume": "CV"
  },
  "hero": {
    "title": "Raphael Partouche",
    "subtitle": "Ing√©nieur Software et √©tudiant en Master Data Science √† Eurecom. Mon parcours se concentre sur l‚Äôapplication du Machine Learning et de l‚ÄôIntelligence Artificielle √† la cr√©ation de solutions √† divers probl√®mes. Mon expertise englobe la conception, le d√©veloppement et le d√©ploiement d‚Äôalgorithmes intelligents ainsi que la conception d‚Äôoutils logiciels exploitant la donn√©e et reposant sur une compr√©hension approfondie des enjeux li√©s √† la performance et √† la g√©n√©ralisation des mod√®les..."
  },
  "about": {
    "title": "",
    "text": ""
  },
  "education": {
    "title": "Formation",
    "eurecom": {
      "title": "EURECOM",
      "subtitle": "Dipl√¥me d‚Äôing√©nieur ‚Äî Master en Data Science",
      "description": "Formation d‚Äôing√©nieur d‚Äôexcellence au c≈ìur du p√¥le technologique de Sophia Antipolis, orient√©e vers la science des donn√©es et l‚Äôintelligence artificielle. J‚Äôy d√©veloppe une expertise solide en apprentissage automatique, bases de donn√©es, Cloud, s√©curit√© des syst√®mes d‚Äôinformation et th√©orie de l‚Äôinformation.\n\n Les enseignements incluent <em><strong> Machine Learning, Database Systems, Cloud, Network Security, Image Processing, Information Theory</strong></em>, mais aussi des disciplines transversales telles que le <em><strong>Droit et le Management</em></strong>.",
      "year": "2024 ‚Äî 2027",
      "city": "Sophia Antipolis, France"
    },
    "jacques": {
      "title": "Lyc√©e Jacques-Decour",
      "subtitle": "Classes pr√©paratoires - PSCI/PSI*",
      "description": "Deux ann√©es de formation intensive en math√©matiques, physique, sciences de l‚Äôing√©nieur et informatique, au sein d‚Äôun environnement acad√©mique s√©lectif et exigeant pr√©parant aux concours d‚Äôentr√©e des grandes √©coles d‚Äôing√©nieurs fran√ßaises. Cette formation, fond√©e sur la rigueur scientifique, la r√©solution de probl√®mes complexes et la ma√Ætrise des raisonnements logiques, d√©veloppe une solide capacit√© d‚Äôabstraction, d‚Äôanalyse et de travail sous pression. Elle m‚Äôa apport√© des bases th√©oriques robustes et une m√©thode de travail efficace, essentielles pour aborder les d√©fis techniques et scientifiques rencontr√©s dans le domaine de l‚Äôing√©nierie.",
      "year": "2022 ‚Äî 2024",
      "city": "Paris, France"
    }
  },
  "experience": {
    "title": "Exp√©rience",
    "civibot": {
      "title": "Ing√©nieur Software",
      "company": "CiviBot",
      "duration": "Juillet 2025 ‚Äî Aujourd‚Äôhui",
      "location": "Hybrid",
      "description": "Ing√©nieur full-stack chez CiviBot, startup incub√©e √† UC Berkeley SkyDeck qui d√©veloppe un assistant IA pour l‚Äôanalyse de documents techniques. J‚Äôinterviens sur l‚Äôensemble de la plateforme : am√©lioration continue de l‚Äôinterface React, √©volution des API FastAPI, et optimisation du module ChatPDF et de son pipeline documentaire. Je contribue √©galement √† la stabilit√©, √† la qualit√© du code et au d√©veloppement de nouvelles fonctionnalit√©s pour accompagner la mont√©e en √©chelle du produit."
    },
    "waterid": {
      "title": "Testeur qualit√©",
      "company": "Water ID",
      "duration": "Juillet 2021",
      "location": "Karlsruhe, Allemagne",
      "description": "Premier stage √† l‚Äô√©tranger et premi√®re exp√©rience en ing√©nierie. Participation aux tests d‚Äô√©tanch√©it√© et de fiabilit√© de dispositifs √©lectroniques destin√©s √† l‚Äôanalyse de la qualit√© de l‚Äôeau des piscines. Implication dans la validation fonctionnelle des prototypes et l‚Äôam√©lioration des proc√©dures de test en environnement industriel."
    }
  },
  "projects": {
    "title": "Projets",
    "civibot": {
    "title": "CiviBot",
    "description": "<strong>CiviBot ‚Äì Projet d‚Äôing√©nierie Full Stack</strong>\n\nCiviBot est une startup incub√©e √† UC Berkeley SkyDeck d√©veloppant un assistant IA pour interroger et interpr√©ter les normes techniques. J‚Äôai contribu√© √† toute la stack ‚Äî frontend, backend et pipeline IA ‚Äî afin de livrer une plateforme coh√©rente et pr√™te pour la production.\n\n<strong>Frontend (React + Ant Design + i18next)</strong>\nRefonte et extension de l‚Äôinterface : navigation dynamique, pages √Ä propos/Contact/Tarifs/Compte, formulaire valid√©, r√©cup√©ration de mot de passe, gestion des abonnements, et internationalisation FR/EN compl√®te.\n\n<strong>Backend (FastAPI + PostgreSQL + Redis + GCS)</strong>\nD√©veloppement d‚ÄôAPI robustes avec validation Pydantic, architecture CRUD modulaire, endpoints pour le contact, la mise √† jour s√©curis√©e du mot de passe et les sessions persistantes ChatPDF. Int√©gration GCS, PostgreSQL et rate limiting Redis.\n\n<strong>Pipeline IA</strong>\nContribution √† l‚Äôingestion documentaire (import ‚Üí parsing ‚Üí embeddings ‚Üí indexation) permettant des r√©ponses sourc√©es et fiables.\n\nCe projet a renforc√© mes comp√©tences full-stack et ma capacit√© √† aligner UX, backend et IA dans un environnement startup.\n\n<strong>Comp√©tences techniques :</strong> <em>React, Ant Design, FastAPI, PostgreSQL, embeddings, recherche vectorielle, i18n</em>"
    },
    "othello": {
      "title": "Othello IA (Navigateur)",
      "description": "<strong>Othello IA ‚Äì Jeu de plateau vocal et intelligent</strong>\n\nCe projet acad√©mique combine la <strong>logique d‚Äôintelligence artificielle</strong> et une <strong>interface web moderne</strong> pour cr√©er un jeu d‚ÄôOthello interactif, jouable en ligne et par commande vocale.\n\n<strong>Interface (React)</strong>\n\nD√©velopp√©e avec React, l‚Äôinterface propose un design fluide et r√©actif, enrichi de th√®mes saisonniers pour une exp√©rience immersive (üåø‚ùÑüå∏‚òÄ). Elle garantit coh√©rence visuelle et interactions intuitives sur toutes les plateformes.\n\n<strong>Syst√®me d‚ÄôIA</strong>\n\nDeux mod√®les d‚ÄôIA ont √©t√© int√©gr√©s pour offrir une strat√©gie √©volu√©e :\n\n- <em>IA Classique (Algorithme Minimax)</em> : une approche d√©terministe simulant plusieurs coups √† l‚Äôavance pour maximiser son avantage tout en limitant celui de l‚Äôadversaire.\n\n- <em>IA Apprentissage automatique (Random Forest Classifier)</em> : entra√Æn√©e sur des donn√©es r√©elles pour pr√©dire les meilleurs coups et s‚Äôam√©liorer en continu par auto-apprentissage.\n\nCette approche hybride associe strat√©gie d√©terministe et intelligence adaptative pour une comparaison de performance √©quilibr√©e.\n\n<strong>Reconnaissance vocale</strong>\n\nGr√¢ce √† <em>Python</em> et √† l‚Äô<em>API Google Speech Recognition</em>, le syst√®me traite les commandes vocales via un filtre passe-bande isolant les fr√©quences de la parole et r√©duisant le bruit. Les commandes reconnues sont ensuite transmises au backend pour ex√©cution.\n\n"
    },
    "sightsense": {
      "title": "Sightsense",
      "description": "<strong>SIGHT Senses ‚Äì Aide √† la navigation portable pour malvoyants</strong>\n\nSIGHT Senses est un projet acad√©mique d‚Äôing√©nierie visant √† concevoir un <strong>syst√®me de guidage portable</strong> destin√© aux personnes malvoyantes. Le dispositif int√®gre <strong>vision par ordinateur</strong>, <strong>audio spatial</strong> et <strong>retour haptique</strong> dans une architecture unifi√©e bas√©e sur un <em>Raspberry Pi</em>, capable de traiter en temps r√©el les informations de l‚Äôenvironnement pour offrir une aide √† la navigation intuitive et multisensorielle.\n\n<strong>Vue d‚Äôensemble du syst√®me</strong>\n\nLe c≈ìur du syst√®me repose sur le Raspberry Pi, qui synchronise trois modules techniques : <em>traitement d‚Äôimage</em>, <em>spatialisation sonore</em> et <em>retour haptique</em>. Chaque module fonctionne de mani√®re autonome tout en √©changeant des donn√©es en continu pour garantir une r√©activit√© imm√©diate. Un script de d√©marrage (<code>crontab</code>) lance automatiquement le programme, rendant le dispositif enti√®rement autonome.\n\n<strong>Traitement d‚Äôimage (Python + OpenCV)</strong>\n\nLe module de vision capture les images de la cam√©ra et r√©alise la <strong>d√©tection en temps r√©el des formes et obstacles</strong>. √Ä l‚Äôaide d‚ÄôOpenCV, il applique des masques de couleur (<code>cv2.inRange()</code>), un flou gaussien pour r√©duire le bruit, puis d√©tecte les contours (<code>cv2.findContours()</code>). Les <em>carr√©s</em> et <em>croix</em> sont identifi√©s via une approximation polygonale (<code>cv2.approxPolyDP()</code>) et un filtrage g√©om√©trique bas√© sur la convexit√© et le ratio d‚Äôaspect. Les lignes bleues sont √©galement d√©tect√©es pour suivre la trajectoire. Seules les formes les plus pertinentes (plus grandes ou centr√©es) sont conserv√©es. Les optimisations vectorielles d‚ÄôOpenCV assurent un traitement fluide et rapide.\n\n<strong>D√©tection de distance et d‚Äôobstacles (Lidar)</strong>\n\nUn capteur <strong>TFLuna Lidar</strong> mesure en continu la distance gr√¢ce √† une communication s√©rie (<code>/dev/serial0</code>). Les variations d√©tect√©es indiquent la pr√©sence d‚Äôobstacles et leur proximit√©. Des seuils dynamiques traduisent la distance en intensit√© de retour sensoriel, coordonnant les r√©ponses haptiques et sonores. Cette int√©gration permet une perception fiable des obstacles, m√™me en faible luminosit√©.\n\n<strong>Traitement audio (Python + PyDub)</strong>\n\nLe <strong>syst√®me audio</strong> convertit les donn√©es spatiales en signaux directionnels. Con√ßu avec PyDub, il ajuste le volume et le d√©lai entre les canaux st√©r√©o pour cr√©er une perception 3D r√©aliste. La fonction <code>balance_sound()</code> module le gain selon la position de l‚Äôobstacle. Chaque type d‚Äôobjet d√©tect√© d√©clenche un son distinct pr√©charg√© (carr√©, croix, ligne, barri√®re), dont le volume varie avec la distance pour fournir un guidage clair et intuitif.\n\n<strong>Retour haptique (Python + RPi.GPIO)</strong>\n\nLe <strong>module haptique</strong> compl√®te les signaux auditifs par des vibrations dont l‚Äôintensit√© d√©pend de la distance. Pilot√© par PWM via les broches GPIO du Raspberry Pi, les fonctions <code>vibrate()</code> et <code>haptic_()</code> produisent des vibrations continues, fortes ou saccad√©es selon la proximit√© de l‚Äôobstacle. Cette redondance sensorielle renforce la fiabilit√© du guidage dans tous les environnements.\n\n<strong>Int√©gration mat√©rielle et mod√©lisation 3D</strong>\n\nLe bo√Ætier, mod√©lis√© sous SolidWorks, regroupe la cam√©ra, le Raspberry Pi, le Lidar, la batterie et les moteurs vibrants dans une unit√© compacte fix√©e sur la poitrine. Des ouvertures assurent la ventilation et des sangles r√©glables garantissent confort et stabilit√©. La conception modulaire facilite la maintenance et l‚Äô√©volution du prototype.\n\nCe projet illustre l‚Äôint√©gration harmonieuse de la <strong>vision par ordinateur</strong>, du <strong>traitement du signal</strong> et des <strong>syst√®mes embarqu√©s</strong> au sein d‚Äôun dispositif portable et intelligent. En synchronisant la vision, le son et le toucher en temps r√©el, SIGHT Senses offre une aide √† la navigation intuitive, robuste et accessible aux personnes malvoyantes."
    },
    "realestate": {
      "title": "Estimation Immobili√®re",
      "description": "<strong>Estimation Immobili√®re ‚Äì Pr√©diction de prix par Machine Learning √† Paris</strong>\n\n<strong>Contexte et Objectifs</strong>\n\nCe projet d√©veloppe un outil web d'estimation de biens immobiliers √† Paris, combinant un mod√®le de machine learning et une interface utilisateur. Le syst√®me s'appuie sur des donn√©es historiques de transactions immobili√®res pour pr√©dire le prix d'un bien √† partir de ses caract√©ristiques principales.\n\n<strong>Traitement des Donn√©es</strong>\n\nLe projet exploite les donn√©es publiques DVF 2024 (Demandes de Valeurs Fonci√®res) du gouvernement fran√ßais, qui recensent l'ensemble des transactions immobili√®res sur le territoire. Ces donn√©es brutes sont pr√©trait√©es dans l'objectif de fournir des valeurs propres et coh√©rentes pour le mod√®le d'apprentissage. Le pr√©traitement nettoie les donn√©es brutes en √©liminant les doublons et valeurs manquantes, convertit les types num√©riques, et enrichit le dataset avec un score de proximit√© aux transports en commun calcul√© via BallTree. De plus, les prix aberrants (>150% de la moyenne par arrondissement) sont filtr√©s afin d'obtenir un dataset coh√©rent pour le mod√®le.\n\n<strong>Machine Learning et Mod√©lisation</strong>\n\nLe mod√®le pr√©dictif utilise l'algorithme Gradient Boosting Regressor de scikit-learn, un ensemble de m√©thodes particuli√®rement efficace pour les probl√®mes de r√©gression. L'architecture comprend 200 arbres de d√©cision (n_estimators=200) avec un taux d'apprentissage mod√©r√© (learning_rate=0.1) et une profondeur maximale de 5 niveaux pour √©viter le surapprentissage. Les features d'entr√©e incluent les coordonn√©es GPS (longitude, latitude) pour la localisation g√©ographique, le code postal, le type de local (maison, appartement, d√©pendance, local commercial), la surface en m¬≤ et le nombre de pi√®ces principales. L'entra√Ænement utilise un split 80/20, et les performances sont √©valu√©es via le coefficient de d√©termination R¬≤, l'erreur absolue moyenne (MAE) et la racine de l'erreur quadratique moyenne (RMSE). Le mod√®le est s√©rialis√© avec joblib pour un d√©ploiement efficace.\n\n<strong>Architecture</strong>\n\nL'application combine un backend FastAPI exposant une API REST et un frontend React moderne avec g√©olocalisation automatique des adresses via l'API Nominatim."
    },
    "ui": {
      "previous": "Projet pr√©c√©dent",
      "next": "Projet suivant",
      "close": "Fermer",
      "previous_image": "Image pr√©c√©dente",
      "next_image": "Image suivante",
      "visit_site": "Consulter le site",
      "view_repo": "Voir le repository"
    }
  },
  "skills": {
    "title": "Comp√©tences"
  }
}
