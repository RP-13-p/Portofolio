{
  "nav": {
    "home": "About",
    "education": "Education",
    "experience": "Experience",
    "projects": "Projects",
    "skills": "Skills",
    "resume": "Resume"
  },
  "footer": {
    "cv": "CV",
    "demo": "Demo",
    "code": "Code",
    "resume": "CV"
  },

  "ui": {
  "read_more": "Read more",
  "read_less": "Read less"
  },

  "hero": {
    "title": "Raphael Partouche",
    "subtitle": "Software Engineer and Master's student in Data Science at Eurecom. My background focuses on applying Machine Learning and Artificial Intelligence to develop solutions for a wide range of problems. My expertise includes the design, development, and deployment of intelligent algorithms, as well as the creation of data-driven software tools built upon a deep understanding of model performance and generalization challenges..."
  },
  "education": {
    "title": "Education",
    "eurecom": {
      "title": "EURECOM",
      "subtitle": "Engineering degree ‚Äî Master in Data Science",
      "description": "High-level engineering program of excellence at the heart of the Sophia Antipolis technology hub, focused on data science and artificial intelligence. I am developing strong expertise in machine learning, databases, cloud computing, information systems security, and information theory.\n\n The curriculum includes <em><strong>Machine Learning, Database Systems, Cloud, Network security, Image processing, and Information theory</em></strong>, as well as cross-disciplinary subjects such as <em><strong>Law and Management</em></strong>.",
      "year": "2024 ‚Äî 2027",
      "city": "Sophia Antipolis, France"
    },
    "jacques": {
      "title": "Lyc√©e Jacques-Decour",
      "subtitle": "Preparatory classes - PSCI/PSI*",
      "description": "Two years of intensive training in mathematics, physics, engineering sciences, and computer science within a highly selective and demanding academic environment, preparing for the national competitive exams to enter top French engineering schools. This program, grounded in scientific rigor, problem-solving, and logical reasoning, fosters strong analytical abilities, abstraction skills, and resilience under pressure. It provided me with solid theoretical foundations and an efficient working methodology, essential for tackling the technical and scientific challenges of engineering.",
      "year": "2022 ‚Äî 2024",
      "city": "Paris, France"
    }
  },
  "experience": {
    "title": "Experience",
    "civibot": {
      "title": "Software Engineer",
      "company": "CiviBot",
      "duration": "July 2025 ‚Äî Present",
      "location": "Hybrid",
      "description": "Full-stack engineer at CiviBot, a UC Berkeley SkyDeck startup building an AI assistant for technical document analysis. I work across the entire platform: improving the React interface, extending FastAPI endpoints, and enhancing the ChatPDF module and its document-processing pipeline. I also contribute to code quality, platform stability, and new feature development as the product continues to scale."
    },
    "waterid": {
      "title": "Product Tester",
      "company": "Water ID",
      "duration": "July 2021 ",
      "location": "Karlsruhe, Germany",
      "description": "First international internship and initial engineering experience. Contributed to waterproofing and reliability testing of electronic devices designed to monitor swimming pool water quality. Involved in prototype validation and optimization of testing procedures within an industrial environment."
    }
  },
  "projects": {
    "title": "Projects",
    "civibot": {
    "title": "CiviBot",
    "description": "<strong>CiviBot ‚Äì Full Stack Engineering Project</strong>\n\nCiviBot is a UC Berkeley SkyDeck‚Äìincubated startup building an AI assistant that helps engineers query and interpret technical standards. I contributed across the full stack ‚Äî frontend, backend, and AI pipeline ‚Äî to deliver a cohesive, production-ready platform.\n\n<strong>Frontend (React + Ant Design + i18next)</strong>\nRefactored and expanded the interface: dynamic navigation, new pages (About, Contact, Pricing, Account), validated contact form, password recovery, subscription flow, and full FR/EN internationalization.\n\n<strong>Backend (FastAPI + PostgreSQL + Redis + GCS)</strong>\nBuilt robust REST APIs with Pydantic validation, structured CRUD architecture, endpoints for contact, secure password updates, and persistent ChatPDF sessions. Integrated GCS storage, PostgreSQL metadata, and Redis rate limiting.\n\n<strong>AI Document Pipeline</strong>\nContributed to ingestion (upload ‚Üí parsing ‚Üí embeddings ‚Üí indexing) enabling grounded, source-linked answers.\n\nThis project strengthened my full-stack skills and my ability to align UX, backend engineering, and AI systems in a startup environment.\n\n<strong>Key Technical Skills:</strong> <em>React, Ant Design, FastAPI, PostgreSQL, embeddings, vector search, i18n</em>"
  }
  ,
    "othello": {
      "title": "Othello AI (Browser)",
      "description": "<strong>Othello AI ‚Äì Speech-Enabled Board Game</strong>\n\nThis academic project integrates <strong>AI logic</strong> and a <strong>modern web interface</strong> to create an interactive Othello game playable both online and by voice.\n\n<strong>Interface (React)</strong>\n\nThe interface, developed with React, offers a smooth, responsive design with seasonal themes for an immersive user experience (üåø‚ùÑüå∏‚òÄ). It ensures visual consistency and intuitive interactions across all platforms.\n\n<strong>AI System</strong>\n\nTwo AI models were implemented to enable strategic gameplay:\n\n- <em>Classic AI (Minimax Algorithm):</em> A rule-based approach that simulates possible moves to maximize advantage while minimizing the opponent‚Äôs options.\n\n- <em>Machine Learning AI (Random Forest Classifier):</em> Trained on real game data to predict optimal moves and continuously improve through self-learning.\n\nThis hybrid setup combines deterministic strategy with adaptive intelligence for performance comparison.\n\n<strong>Speech Recognition</strong>\n\nUsing <em>Python</em> and the <em>Google Speech Recognition API</em>, the system processes spoken commands through a band-pass filter to isolate speech frequencies and reduce noise. Recognized commands are then sent to the backend for action.<strong>\n\n"
    },
    "sightsense": {
      "title": "Sightsenses",
      "description": "<strong>SIGHT Senses ‚Äì Wearable Navigation Aid for the Visually Impaired</strong>\n\nSIGHT Senses is an academic engineering project focused on developing a <strong>wearable guidance system</strong> for visually impaired users. The device integrates <strong>computer vision</strong>, <strong>spatial audio</strong>, and <strong>haptic feedback</strong> into a unified architecture powered by a <em>Raspberry Pi</em>. It processes environmental information in real time to provide intuitive, multisensory navigation assistance.\n\n<strong>System Overview</strong>\n\nThe core system is structured around the Raspberry Pi, which synchronizes three technical modules: <em>image processing</em>, <em>sound spatialization</em>, and <em>haptic feedback</em>. Each module operates independently but exchanges data continuously to ensure real-time reactivity. A startup script (<code>crontab</code>) allows the device to launch automatically and operate autonomously once powered on.\n\n<strong>Image Processing (Python + OpenCV)</strong>\n\nThe vision module captures frames from the onboard camera and performs real-time <strong>shape and obstacle detection</strong>. Using OpenCV, it applies color-based segmentation (<code>cv2.inRange()</code>), Gaussian blur for noise reduction, and contour extraction (<code>cv2.findContours()</code>). It identifies <em>squares</em> and <em>crosses</em> via polygon approximation (<code>cv2.approxPolyDP()</code>) and geometric filtering (convexity, aspect ratio). Blue lines are also detected for path alignment. Once detected, the position and type of each element are transmitted to the feedback modules. For efficiency, only the most relevant shapes (largest or most centered) are kept, and vectorized OpenCV operations ensure fast computation.\n\n<strong>Distance and Obstacle Detection (Lidar)</strong>\n\nA <strong>TFLuna Lidar</strong> sensor continuously measures distances via serial communication (<code>/dev/serial0</code>). The readings are analyzed to detect obstacles and quantify proximity. Dynamic thresholds translate distance into feedback intensity, synchronizing the haptic and audio responses. This enables continuous awareness of surrounding obstacles, even in low-light or visually complex environments.\n\n<strong>Audio Processing (Python + PyDub)</strong>\n\nThe <strong>audio feedback system</strong> translates spatial data into directional cues. Built with PyDub, it adjusts stereo balance and timing to simulate a realistic 3D perception of the environment. The <code>balance_sound()</code> function modulates gain and delay between left and right channels depending on the obstacle‚Äôs position. Each type of detected object triggers a distinct preloaded sound (square, cross, line, fence), and the volume varies according to distance, offering clear and natural guidance through spatial hearing.\n\n<strong>Haptic Feedback (Python + RPi.GPIO)</strong>\n\nThe <strong>haptic subsystem</strong> complements the audio cues by converting distance data into tactile signals. Controlled via PWM on the Raspberry Pi GPIO, the <code>vibrate()</code> and <code>haptic_()</code> functions generate vibrations of variable frequency and intensity. The closer the obstacle, the stronger and more intermittent the vibration, providing an intuitive sense of spatial proximity. This dual-sensory redundancy (audio + touch) ensures reliable feedback in noisy or distracting environments.\n\n<strong>Hardware Integration and 3D Design</strong>\n\nThe device‚Äôs housing was modeled in SolidWorks for ergonomic and modular assembly. It contains the Raspberry Pi, Lidar, camera, battery, and vibration motors in a compact chest-mounted unit. Ventilation channels prevent overheating, while adjustable straps ensure user comfort and correct sensor alignment. The modular structure allows easy replacement and maintenance of components.\n\nThis project demonstrates the seamless integration of <strong>AI-driven perception</strong>, <strong>signal processing</strong>, and <strong>embedded systems</strong> within a wearable navigation device. The system operates autonomously, synchronizing image, sound, and haptic feedback in real time to deliver intuitive and reliable guidance for visually impaired individuals.\n\n"
    },
    "realestate": {
      "title": "Real Estate Estimation",
      "description": "<strong>Real Estate Estimation ‚Äì Machine Learning Price Prediction for Paris</strong>\n\n<strong>Context and Objectives</strong>\n\nThis project develops a web-based tool for estimating the value of Parisian real estate, combining a machine learning model with a user interface. The system relies on historical real estate transaction data to predict the price of a property based on its main characteristics.\n\n<strong>Data Processing</strong>\n\nThe project uses the public DVF 2024 data (Demandes de Valeurs Fonci√®res) from the French government, which lists all real estate transactions in the country. These raw data are preprocessed with the objective of providing clean and consistent values for the learning model. The preprocessing cleans the raw data by removing duplicates and missing values, converts numerical types, and enriches the dataset with a public transportation proximity score calculated using BallTree. In addition, aberrant prices (>150% of the district average) are filtered out to obtain a coherent dataset for the model.\n\n<strong>Machine Learning and Modeling</strong>\n\nThe predictive model uses the Gradient Boosting Regressor algorithm from scikit-learn, an ensemble method particularly effective for regression problems. The architecture includes 200 decision trees (n_estimators=200) with a moderate learning rate (learning_rate=0.1) and a maximum depth of 5 levels to avoid overfitting. The input features include GPS coordinates (longitude, latitude) for geographic localization, postal code, type of property (house, apartment, dependency, commercial unit), surface area in m¬≤, and the number of main rooms. Training uses an 80/20 split, and performance is evaluated using the R¬≤ coefficient of determination, the mean absolute error (MAE), and the root mean squared error (RMSE). The model is serialized with joblib for efficient deployment.\n\n<strong>Architecture</strong>\n\nThe application combines a FastAPI backend exposing a REST API and a modern React frontend with automatic address geolocation via the Nominatim API."
    },
    "ui": {
      "previous": "Previous project",
      "next": "Next project",
      "close": "Close",
      "previous_image": "Previous image",
      "next_image": "Next image",
      "visit_site": "Visit site",
      "view_repo": "View repository"
    }
  },
  "skills": {
    "title": "Skills"
  }
}